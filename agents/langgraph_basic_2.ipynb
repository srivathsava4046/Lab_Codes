{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-openai langchain-community langgraph"
      ],
      "metadata": {
        "id": "2ORZn5szTBOp",
        "outputId": "7caeae50-bc6b-4eb7-ddb9-feb376ff0da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2ORZn5szTBOp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "9SJZxgfMVu9h",
        "outputId": "7439265e-9e1e-455b-a98b-5315c7f4b045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9SJZxgfMVu9h",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.8.3)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=08fdda8b358f7fd687c4d14171d6b93ae9a01c3ed450d16e713ddef57c928337\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e493821a",
      "metadata": {
        "id": "e493821a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Literal\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain.chains import LLMMathChain\n",
        "from langgraph.graph import StateGraph, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "376ccf7c",
      "metadata": {
        "id": "376ccf7c"
      },
      "outputs": [],
      "source": [
        "# --- Environment and LLM Setup ---\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"28c7641827dc44957197ef674a2945932ec69475db9f5b7af4ab08fe9d6fbff5\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    api_key=\"KEY\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    model=\"deepseek/deepseek-chat-v3.1:free\",\n",
        "    temperature=0.7,\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "# --- Tool Definitions ---\n",
        "search_tool = SerpAPIWrapper()\n",
        "math_tool = LLMMathChain.from_llm(llm=llm, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ccce833b",
      "metadata": {
        "id": "ccce833b"
      },
      "outputs": [],
      "source": [
        "# --- State Definition ---\n",
        "# Updated state to include a route for travel and a result.\n",
        "class AgentState(TypedDict):\n",
        "    topic: str\n",
        "    explanation: str\n",
        "    summary: str\n",
        "    calculator_result: str\n",
        "    travel_result: str\n",
        "    route: Literal[\"research\", \"calculate\", \"travel\"] # The planner's decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2a3ff5d2",
      "metadata": {
        "id": "2a3ff5d2"
      },
      "outputs": [],
      "source": [
        "def planner_agent(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent decides whether the user's topic is a math, research, or travel question.\n",
        "    \"\"\"\n",
        "    print(\"---PLANNER---\")\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"You are a planner agent. Your job is to determine the best path to take based on the user's query.\n",
        "\n",
        "        Query: {topic}\n",
        "\n",
        "        Based on the query, is this a math problem, a travel-related query (like finding hotels or flights), or a general research question?\n",
        "        Respond with 'calculate', 'travel', or 'research'.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"topic\": topic})\n",
        "    decision = result.content.strip().lower()\n",
        "\n",
        "    print(f\"Planner's Decision: {decision}\")\n",
        "    if \"calculate\" in decision:\n",
        "        return {\"route\": \"calculate\"}\n",
        "    elif \"travel\" in decision:\n",
        "        return {\"route\": \"travel\"}\n",
        "    else:\n",
        "        return {\"route\": \"research\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3f50cb12",
      "metadata": {
        "id": "3f50cb12"
      },
      "outputs": [],
      "source": [
        "def researcher_agent(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent uses a web search tool to find information on a topic and then explains it.\n",
        "    \"\"\"\n",
        "    print(\"---RESEARCHER (with SerpApi Web Search)---\")\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    search_results = search_tool.run(topic)\n",
        "    print(f\"Search Results:\\n{search_results}\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"You are a helpful research assistant. Based on the following search results,\n",
        "        provide a brief, easy-to-understand explanation of the topic: {topic}.\n",
        "\n",
        "        Search Results:\n",
        "        {search_results}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"topic\": topic, \"search_results\": search_results})\n",
        "\n",
        "    print(f\"Researcher's Explanation:\\n{result.content}\")\n",
        "    return {\"explanation\": result.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9b4123bd",
      "metadata": {
        "id": "9b4123bd"
      },
      "outputs": [],
      "source": [
        "def calculator_agent(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent uses an LLM Math tool to solve a math problem.\n",
        "    \"\"\"\n",
        "    print(\"---CALCULATOR---\")\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    result = math_tool.invoke({\"question\": topic})\n",
        "    answer = result.get('answer', 'Could not calculate answer.')\n",
        "\n",
        "    print(f\"Calculator's Result: {answer}\")\n",
        "    return {\"calculator_result\": answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8f6f49d5",
      "metadata": {
        "id": "8f6f49d5"
      },
      "outputs": [],
      "source": [
        "def travel_planner_agent(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent searches for travel-related information like hotels or flights.\n",
        "    \"\"\"\n",
        "    print(\"---TRAVEL PLANNER---\")\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # For this example, we'll just use the general search tool.\n",
        "    # A real-world application would use a dedicated travel API.\n",
        "    search_results = search_tool.run(f\"Find information about: {topic}\")\n",
        "\n",
        "    print(f\"Travel Search Results:\\n{search_results}\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"You are a helpful travel assistant. Summarize the following information for the user's travel query about '{topic}'.\n",
        "\n",
        "        Search Results:\n",
        "        {search_results}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"topic\": topic, \"search_results\": search_results})\n",
        "\n",
        "    print(f\"Travel Planner's Response:\\n{result.content}\")\n",
        "    return {\"travel_result\": result.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c7ee4f56",
      "metadata": {
        "id": "c7ee4f56"
      },
      "outputs": [],
      "source": [
        "def summarizer_agent(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    This agent takes an explanation and summarizes it in one sentence.\n",
        "    \"\"\"\n",
        "    print(\"---SUMMARIZER---\")\n",
        "    explanation = state[\"explanation\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"You are a summarization expert. Condense the following text into a single, concise sentence:\\n\\n{explanation}\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"explanation\": explanation})\n",
        "\n",
        "    print(f\"Summarizer's Output:\\n{result.content}\")\n",
        "    return {\"summary\": result.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "27b382a1",
      "metadata": {
        "id": "27b382a1"
      },
      "outputs": [],
      "source": [
        "# --- Conditional Routing Function ---\n",
        "def should_route(state: AgentState) -> Literal[\"research\", \"calculate\", \"travel\"]:\n",
        "    \"\"\"This function is the decision point for our conditional edge.\"\"\"\n",
        "    return state[\"route\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5179a4c9",
      "metadata": {
        "id": "5179a4c9"
      },
      "outputs": [],
      "source": [
        "# --- Graph Definition ---\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add all the agent functions as nodes\n",
        "workflow.add_node(\"planner\", planner_agent)\n",
        "workflow.add_node(\"researcher\", researcher_agent)\n",
        "workflow.add_node(\"calculator\", calculator_agent)\n",
        "workflow.add_node(\"travel_planner\", travel_planner_agent)\n",
        "workflow.add_node(\"summarizer\", summarizer_agent)\n",
        "\n",
        "# Set the entry point to the planner\n",
        "workflow.set_entry_point(\"planner\")\n",
        "\n",
        "# Add the conditional edge for the planner\n",
        "workflow.add_conditional_edges(\n",
        "    \"planner\",\n",
        "    should_route,\n",
        "    {\n",
        "        \"research\": \"researcher\",\n",
        "        \"calculate\": \"calculator\",\n",
        "        \"travel\": \"travel_planner\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define the standard edges\n",
        "workflow.add_edge(\"researcher\", \"summarizer\")\n",
        "workflow.add_edge(\"summarizer\", END)\n",
        "workflow.add_edge(\"calculator\", END)\n",
        "workflow.add_edge(\"travel_planner\", END) # Travel result is final\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0dda408d",
      "metadata": {
        "id": "0dda408d",
        "outputId": "604f9e7c-0521-4106-afee-fac9c97640ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a topic, math problem, or travel query: Interstellar\n",
            "---PLANNER---\n",
            "Planner's Decision: research\n",
            "---RESEARCHER (with SerpApi Web Search)---\n",
            "Search Results:\n",
            "[\"In Earth's future, a global crop blight and second Dust Bowl are slowly rendering the planet uninhabitable. Professor Brand (Michael Caine), a brilliant NASA physicist, is working on plans to save mankind by transporting Earth's population to a new home via a wormhole. But first, Brand must send former NASA pilot Cooper (Matthew McConaughey) and a team of researchers through the wormhole and across the galaxy to find out which of three planets could be mankind's new home.… MORE\", 'Interstellar type: PG-13 2014 ‧ Sci-fi/Adventure ‧ 2h 49m.', 'Interstellar entity_type: film, tvm.', 'Interstellar kgmid: /m/0fkf28.', 'Interstellar release_date: October 26, 2014 (USA).', 'Interstellar director: Christopher Nolan.', 'Interstellar running_time: 2h 49m.', 'Interstellar music_composed_by: Hans Zimmer.', 'Interstellar budget: 165 million USD (2013).', 'Interstellar awards: Academy Award for Best Visual Effects.', 'The film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.', 'A group of explorers make use of a newly discovered wormhole to surpass the limitations on human space travel and conquer the vast distances involved in an ...', 'With humanity teetering on the brink of extinction, a group of astronauts travels through a wormhole in search of another inhabitable planet.', \"Based on scientific theories of CalTech physicist Kip Thorne, Nolan's deep space opus depicts a heroic interstellar voyage to the very edge of the universe.\", \"A brilliant NASA physicist is working on plans to save mankind by transporting Earth's population to a new home via a wormhole.\", \"A team of explorers travel through a wormhole in an attempt to ensure humanity's survival. Now on 4K Ultra HD, Blu-ray and Digital. Also streaming on @ ...\", 'Listen to Interstellar (Original Motion Picture Soundtrack) [Expanded Edition] on Spotify · album · Hans Zimmer · 2014 · 30 songs.', 'The adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on human space travel and conquer the vast ...']\n",
            "Researcher's Explanation:\n",
            "Of course. Based on the search results, here is a simple explanation of **Interstellar**.\n",
            "\n",
            "**Interstellar** is a science fiction adventure film directed by Christopher Nolan.\n",
            "\n",
            "The story is set in a future where Earth is becoming uninhabitable due to environmental disasters. To save humanity, a team of astronauts is sent on a mission through a **wormhole** (a theoretical tunnel in space-time) near Saturn.\n",
            "\n",
            "Their goal is to explore distant galaxies and find a new planet where humans can live. The film is famous for its stunning visuals, emotional story, and its attempt to be scientifically accurate, basing its concepts on real theories from a renowned physicist.\n",
            "\n",
            "In short, it's an epic movie about a desperate journey across the universe to find a new home for the human race.\n",
            "---SUMMARIZER---\n",
            "Summarizer's Output:\n",
            "Christopher Nolan's \"Interstellar\" is an epic sci-fi film about astronauts traveling through a wormhole to find a new habitable planet for a dying humanity.\n",
            "\n",
            "--- FINAL RESULT ---\n",
            "Christopher Nolan's \"Interstellar\" is an epic sci-fi film about astronauts traveling through a wormhole to find a new habitable planet for a dying humanity.\n"
          ]
        }
      ],
      "source": [
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    topic = input(\"Please enter a topic, math problem, or travel query: \")\n",
        "\n",
        "    inputs = {\"topic\": topic}\n",
        "    final_state = app.invoke(inputs)\n",
        "\n",
        "    print(\"\\n--- FINAL RESULT ---\")\n",
        "    # The final result depends on which path was taken\n",
        "    if final_state.get('summary'):\n",
        "        print(final_state['summary'])\n",
        "    elif final_state.get('calculator_result'):\n",
        "        print(final_state['calculator_result'])\n",
        "    elif final_state.get('travel_result'):\n",
        "        print(final_state['travel_result'])\n",
        "    else:\n",
        "        print(\"An unexpected error occurred.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-8guVU0WQaR"
      },
      "id": "a-8guVU0WQaR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}